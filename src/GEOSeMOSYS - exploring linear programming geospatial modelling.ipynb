{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEOSeMOSYS - exploring linear programming geospatial energy modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nandi Moksnes, Mark Howells............"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is dectription of how to reproduce the results in the paper:\n",
    "For any questions please contact Nandi Moksnes: nandi@kth.se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The files in \"GIS_data\" are downloaded and placed in a \"temp\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Download_files.py import *\n",
    "\n",
    "download_url_data(input_data/GIS_URL.txt temp)\n",
    "unzip_all(input_data/GIS_URL.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The files are then projected and clipped to the administrative boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Project_GIS import *\n",
    "merge_minigrid('..\\Projected_files')\n",
    "\n",
    "#main('../GIS_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Through QGIS make raster to point layer and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) masked_UMT37S_ken_ppp_2015_UNadj: SAGA raster to point \n",
    "\n",
    "2) This step is\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The GIS layers are prepared to for a heuristic approximation for electrified settlements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settlement_build import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import gridded file from Zenodo for Kenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Download_files import *\n",
    "\n",
    "download_url_data('input_data/zenodo.txt', '../Projected_files')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One central part of the geospatial energy modelling dimension is assessing the energy resources at the location. This is done through the capacity factors from renewable.ninja for wind and solar PV for each of the 376 cells downloaded from zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "token = 'ed519952eff7850cece8c746347fee2d068ab988'\n",
    "type = \"solar\"\n",
    "\n",
    "j = 0\n",
    "max_hour =3601\n",
    "start_hour = time.time()\n",
    "while True:\n",
    "    ### Do other stuff, it won't be blocked\n",
    "    time.sleep(0.1)\n",
    "    print(\"looping...\")\n",
    "\n",
    "    ### This will be updated every loop\n",
    "    remaining_hour = max_hour + start_hour - time.time()\n",
    "    print(\"%s seconds remaining\" % int(remaining_hour))\n",
    "\n",
    "    ### Countdown finished, ending loop\n",
    "    if remaining_hour <= 0:\n",
    "        break\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    max = 60\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        token_ = \"ed519952eff7850cece8c746347fee2d068ab988\"\n",
    "        type = \"wind\"\n",
    "        ### Do other stuff, it won't be blocked\n",
    "        time.sleep(0.1)\n",
    "        print(\"looping...\")\n",
    "\n",
    "        ### This will be updated every loop\n",
    "        remaining = max + start - time.time()\n",
    "        print(\"%s seconds remaining\" % int(remaining))\n",
    "\n",
    "        ### Countdown finished, ending loop\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "\n",
    "        while count <=6:\n",
    "            csvfiles = r'.\\temp\\solar1-6.csv'\n",
    "            csvfilesout = r'.\\temp\\solar1-6_out.csv'\n",
    "            subprocess.call(\"RScript GEOSeMOSYS_download.r\"+\" \"+ token_+\" \"+type+\" \"+ csvfiles+\" \"+csvfilesout, shell=True)\n",
    "            count +=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The GIS files needs to be scaled down to a gridded dataset for populating the GIS attributes to estimate the electrified settelments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is modified from https://github.com/babakkhavari/OnSSET-GIS-Extraction\n",
    "#This section creates raster to point, and assigns the different transmission lines and nightime lights to the same geopandas df\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import rasterio.fill\n",
    "from shapely.geometry import shape, mapping\n",
    "import json\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import gdal\n",
    "import datetime\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import scipy.spatial\n",
    "from osgeo import gdal,ogr\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)\n",
    "def settlement_process():\n",
    "    open()\n",
    "\n",
    "    return()\n",
    "\n",
    "#måste lösas först\n",
    "def raster_to_numpyarray():  # make raster to point\n",
    "    pop_file = os.path.join(Projected_files_path+r'\\masked_UMT37S_ken_ppp_2015_UNadj.TIF')\n",
    "    pop_shp = os.path.join(Projected_files_path+r'\\pop.shp')\n",
    "\n",
    "    def pixelOffset2coord(raster, xOffset, yOffset):\n",
    "        geotransform = raster.GetGeoTransform()\n",
    "        originX = geotransform[0]\n",
    "        originY = geotransform[3]\n",
    "        pixelWidth = geotransform[1]\n",
    "        pixelHeight = geotransform[5]\n",
    "        coordX = originX + pixelWidth * xOffset\n",
    "        coordY = originY + pixelHeight * yOffset\n",
    "        return coordX, coordY\n",
    "\n",
    "    def raster2array(rasterfn):\n",
    "        raster = gdal.Open(rasterfn)\n",
    "        band = raster.GetRasterBand(1)\n",
    "        array = band.ReadAsArray()\n",
    "        return array\n",
    "\n",
    "    def array2shp(array, outSHPfn, rasterfn):\n",
    "\n",
    "        # max distance between points\n",
    "        raster = gdal.Open(rasterfn)\n",
    "        geotransform = raster.GetGeoTransform()\n",
    "        pixelWidth = geotransform[1]\n",
    "\n",
    "        # wkbPoint\n",
    "        shpDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "        if os.path.exists(outSHPfn):\n",
    "            shpDriver.DeleteDataSource(outSHPfn)\n",
    "        outDataSource = shpDriver.CreateDataSource(outSHPfn)\n",
    "        outLayer = outDataSource.CreateLayer(outSHPfn, geom_type=ogr.wkbPoint)\n",
    "        featureDefn = outLayer.GetLayerDefn()\n",
    "        outLayer.CreateField(ogr.FieldDefn(\"ID\", ogr.OFTInteger))\n",
    "\n",
    "        # array2dict\n",
    "        point = ogr.Geometry(ogr.wkbPoint)\n",
    "        row_count = array.shape[0]\n",
    "        for ridx, row in enumerate(array):\n",
    "            if ridx % 100 == 0:\n",
    "                print(\"{0} of {1} rows processed\".format(ridx, row_count))\n",
    "            for cidx, value in enumerate(row):\n",
    "                Xcoord, Ycoord = pixelOffset2coord(raster, cidx, ridx)\n",
    "                point.AddPoint(Xcoord, Ycoord)\n",
    "                outFeature = ogr.Feature(featureDefn)\n",
    "                outFeature.SetGeometry(point)\n",
    "                outLayer.CreateFeature(outFeature)\n",
    "                outFeature.SetField(\"ID\", outFeature.GetFID())\n",
    "                outLayer.SetFeature(outFeature)\n",
    "                outFeature.Destroy()\n",
    "        outDataSource.Destroy()\n",
    "\n",
    "    array = raster2array(pop_file)\n",
    "    array2shp(array, pop_shp, pop_file)\n",
    "\n",
    "\n",
    "\n",
    "# messagebox.showinfo('OnSSET', 'Select the clusters')\n",
    "# clusters = gpd.read_file(filedialog.askopenfilename(filetypes=((\"shapefile\", \"*.shp\"), (\"all files\", \"*.*\"))))\n",
    "#\n",
    "# ##widget ta bort - peka mot Population\n",
    "# popunit = widgets.Dropdown(options=clusters.head(),\n",
    "#                            value=None,\n",
    "#                            description='Population:',\n",
    "#                            disabled=False)\n",
    "# display(popunit)\n",
    "# x = popunit.value\n",
    "\n",
    "\n",
    "\n",
    "#Geopandas code Babak\n",
    "# #Processing Rasters\n",
    "#for nighttime light\n",
    "def processing_raster(name, method, clusters):\n",
    "    messagebox.showinfo('OnSSET', 'Select the ' + name + ' map')\n",
    "    raster = rasterio.open(filedialog.askopenfilename(filetypes=((\"rasters\", \"*.tif\"), (\"all files\", \"*.*\"))))\n",
    "\n",
    "    clusters = zonal_stats(\n",
    "        clusters,\n",
    "        raster.name,\n",
    "        stats=[method],\n",
    "        prefix=name, geojson_out=True, all_touched=True)\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    return clusters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Finalizing rasters\n",
    "#Zonal statistics geopandas output is not a dataframe\n",
    "def finalizing_rasters(workspace, clusters, crs):\n",
    "    output = workspace + r'\\placeholder.geojson'\n",
    "    with open(output, \"w\") as dst:\n",
    "        collection = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": list(clusters)}\n",
    "        dst.write(json.dumps(collection))\n",
    "\n",
    "    clusters = gpd.read_file(output)\n",
    "    os.remove(output)\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    return clusters\n",
    "\n",
    "#Preparing for vectors\n",
    "def preparing_for_vectors(workspace, clusters, crs):\n",
    "    clusters.crs = {'init' :'epsg:4326'}\n",
    "    clusters = clusters.to_crs({ 'init': crs})\n",
    "    points = clusters.copy()\n",
    "    points[\"geometry\"] = points[\"geometry\"].centroid\n",
    "    points.to_file(workspace + r'\\clusters_cp.shp', driver='ESRI Shapefile')\n",
    "    print(datetime.datetime.now())\n",
    "    return clusters\n",
    "\n",
    "#Processing Lines\n",
    "#Geopandas kan inte hantera lines så det blir points\n",
    "def processing_lines(name, admin, crs, workspace, clusters):\n",
    "    messagebox.showinfo('OnSSET', 'Select the ' + name + ' map')\n",
    "    lines = gpd.read_file(filedialog.askopenfilename(filetypes=((\"shapefile\", \"*.shp\"), (\"all files\", \"*.*\"))))\n",
    "\n",
    "    lines_clip = clip.clip_shp(lines, admin)\n",
    "    lines_clip.crs = {'init': 'epsg:4326'}\n",
    "    lines_proj = lines_clip.to_crs({'init': crs})\n",
    "\n",
    "    lines_proj.to_file(workspace + r\"\\ \" + name + \"_proj.shp\", driver='ESRI Shapefile')\n",
    "\n",
    "    line = fiona.open(workspace + r\"\\ \" + name + \"_proj.shp\")\n",
    "    firstline = line.next()\n",
    "\n",
    "    schema = {'geometry': 'Point', 'properties': {'id': 'int'}, }\n",
    "    with fiona.open(workspace + r\"\\ \" + name + \"_proj_points.shp\", \"w\", \"ESRI Shapefile\", schema) as output:\n",
    "        for lines in line:\n",
    "            if lines[\"geometry\"] is not None:\n",
    "                first = shape(lines['geometry'])\n",
    "                length = first.length\n",
    "                for distance in range(0, int(length), 100):\n",
    "                    point = first.interpolate(distance)\n",
    "                    output.write({'geometry': mapping(point), 'properties': {'id': 1}})\n",
    "\n",
    "    lines_f = fiona.open(workspace + r\"\\ \" + name + \"_proj_points.shp\")\n",
    "    lines = gpd.read_file(workspace + r\"\\ \" + name + \"_proj.shp\")\n",
    "    points = fiona.open(workspace + r'\\clusters_cp.shp')\n",
    "\n",
    "    ##\n",
    "    geoms1 = [shape(feat[\"geometry\"]) for feat in lines_f]\n",
    "    s1 = [np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geoms1]\n",
    "    s1_arr = np.array(s1)\n",
    "\n",
    "    geoms2 = [shape(feat[\"geometry\"]) for feat in points]\n",
    "    s2 = [np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geoms2]\n",
    "    s2_arr = np.array(s2)\n",
    "\n",
    "    def do_kdtree(combined_x_y_arrays, points):\n",
    "        mytree = scipy.spatial.cKDTree(combined_x_y_arrays)\n",
    "        dist, indexes = mytree.query(points)\n",
    "        return dist, indexes\n",
    "\n",
    "    ##ger alla vektorer som overlappar med linje. TA BORT!!!!\n",
    "    def vector_overlap(vec, settlementfile, column_name):\n",
    "        vec.drop(vec.columns.difference([\"geometry\"]), 1, inplace=True)\n",
    "        a = gpd.sjoin(settlementfile, vec, op='intersects')\n",
    "        a[column_name + '2'] = 0\n",
    "        return a\n",
    "\n",
    "    results1, results2 = do_kdtree(s1_arr, s2_arr)\n",
    "\n",
    "    z = results1.tolist()\n",
    "    clusters[name + 'Dist'] = z\n",
    "    clusters[name + 'Dist'] = clusters[name + 'Dist'] / 1000\n",
    "\n",
    "    ##Ta bort\n",
    "    a = vector_overlap(lines, clusters, name + 'Dist')\n",
    "\n",
    "    ##ta bort\n",
    "    clusters = pd.merge(left=clusters, right=a[['id', name + 'Dist2']], on='id', how='left')\n",
    "    clusters.drop_duplicates(subset=\"id\", keep=\"first\", inplace=True)\n",
    "\n",
    "    ## ta bort\n",
    "    clusters.loc[clusters[name + 'Dist2'] == 0, name + 'Dist'] = 0\n",
    "\n",
    "    # ta bort\n",
    "    del clusters[name + 'Dist2']\n",
    "    print(datetime.datetime.now())\n",
    "    return clusters\n",
    "\n",
    "#Processing points\n",
    "def processing_points(name, admin, crs, workspace, clusters):\n",
    "    messagebox.showinfo('OnSSET', 'Select the ' + name + ' map')\n",
    "    points = gpd.read_file(filedialog.askopenfilename(filetypes=((\"shapefile\", \"*.shp\"), (\"all files\", \"*.*\"))))\n",
    "\n",
    "    points_clip = clip.clip_shp(points, admin)\n",
    "    points_clip.crs = {'init': 'epsg:4326'}\n",
    "    points_proj = points_clip.to_crs({'init': crs})\n",
    "\n",
    "    points_proj.to_file(workspace + r\"\\ \" + name + \"_proj.shp\", driver='ESRI Shapefile')\n",
    "\n",
    "    points_f = fiona.open(workspace + r\"\\ \" + name + \"_proj.shp\")\n",
    "    points = gpd.read_file(workspace + r\"\\ \" + name + \"_proj.shp\")\n",
    "    points2 = fiona.open(workspace + r'\\clusters_cp.shp')\n",
    "\n",
    "    geoms1 = [shape(feat[\"geometry\"]) for feat in points_f]\n",
    "    s1 = [np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geoms1]\n",
    "    s1_arr = np.array(s1)\n",
    "\n",
    "    geoms2 = [shape(feat[\"geometry\"]) for feat in points2]\n",
    "    s2 = [np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geoms2]\n",
    "    s2_arr = np.array(s2)\n",
    "\n",
    "    def do_kdtree(combined_x_y_arrays, points):\n",
    "        mytree = scipy.spatial.cKDTree(combined_x_y_arrays)\n",
    "        dist, indexes = mytree.query(points)\n",
    "        return dist, indexes\n",
    "\n",
    "    ##Ta bort\n",
    "    def vector_overlap(vec, settlementfile, column_name):\n",
    "        vec.drop(vec.columns.difference([\"geometry\"]), 1, inplace=True)\n",
    "        a = gpd.sjoin(settlementfile, vec, op='intersects')\n",
    "        a[column_name + '2'] = 0\n",
    "        return a\n",
    "\n",
    "    results1, results2 = do_kdtree(s1_arr, s2_arr)\n",
    "\n",
    "    z = results1.tolist()\n",
    "    clusters[name + 'Dist'] = z\n",
    "    clusters[name + 'Dist'] = clusters[name + 'Dist'] / 1000\n",
    "\n",
    "    # ta bort\n",
    "    a = vector_overlap(points, clusters, name + 'Dist')\n",
    "\n",
    "    # ta bort\n",
    "    clusters = pd.merge(left=clusters, right=a[['id', name + 'Dist2']], on='id', how='left')\n",
    "    clusters.drop_duplicates(subset=\"id\", keep=\"first\", inplace=True)\n",
    "    # ta bort\n",
    "    clusters.loc[clusters[name + 'Dist2'] == 0, name + 'Dist'] = 0\n",
    "    # ta bort\n",
    "    del clusters[name + 'Dist2']\n",
    "    print(datetime.datetime.now())\n",
    "    return clusters\n",
    "\n",
    "#Conditioning\n",
    "def conditioning(clusters, workspace, popunit):\n",
    "    clusters = clusters.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "    clusters = clusters.rename(columns={\"NightLight\": \"NightLights\", popunit: \"Pop\", \"GridCellAr\": \"GridCellArea\"})\n",
    "\n",
    "    if \"landcovermajority\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"landcovermajority\": \"LandCover\"})\n",
    "\n",
    "    if \"elevationmean\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"elevationmean\": \"Elevation\"})\n",
    "\n",
    "    if \"sl_majority\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"sl_majority\": \"Slope\"})\n",
    "\n",
    "    if \"ghimean\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"ghimean\": \"GHI\"})\n",
    "\n",
    "    if \"traveltimemean\" in clusters:\n",
    "        clusters[\"traveltimemean\"] = clusters[\"traveltimemean\"] / 60\n",
    "        clusters = clusters.rename(columns={\"traveltimemean\": \"TravelHours\"})\n",
    "    elif \"TravelHour\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"TravelHour\": \"TravelHours\"})\n",
    "\n",
    "    if \"windmean\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"windmean\": \"WindVel\"})\n",
    "\n",
    "    if \"Residentia\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"Resudentia\": \"ResidentialDemandTierCustom\"})\n",
    "    elif \"customdemandmean\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"customdemandmean\": \"ResidentialDemandTierCustom\"})\n",
    "    else:\n",
    "        clusters[\"ResidentialDemandTierCustom\"] = 0\n",
    "\n",
    "    if \"Substation\" in clusters:\n",
    "        clusers = clusters.rename(columns={\"Substation\": \"SubstationDist\"})\n",
    "    elif \"SubstationDist\" not in clusters:\n",
    "        clusters[\"SubstationDist\"] = 99\n",
    "\n",
    "    if \"CurrentHVL\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"CurrentHVL\": \"Existing_HVDist\"})\n",
    "\n",
    "    if \"CurrentMVL\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"CurrentMVL\": \"Existing_MVDist\"})\n",
    "\n",
    "    if \"PlannedHVL\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"PlannedHVL\": \"Planned_HVDist\"})\n",
    "\n",
    "    if \"PlannedMVL\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"PlannedMVL\": \"Planned_MVDist\"})\n",
    "\n",
    "    if \"Existing_HVDist\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"Existing_HVDist\": \"CurrentHVLineDist\"})\n",
    "        if \"Planned_HVDist\" in clusters:\n",
    "            mask = (clusters['Planned_HVDist'] > clusters['CurrentHVLineDist'])\n",
    "            clusters['Planned_HVDist'][mask] = clusters['CurrentHVLineDist']\n",
    "            clusters = clusters.rename(columns={\"Planned_HVDist\": \"PlannedHVLineDist\"})\n",
    "        else:\n",
    "            clusters[\"PlannedHVLineDist\"] = clusters[\"CurrentHVLineDist\"]\n",
    "    elif \"Existing_HVDist\" not in clusters and \"Planned_HVDist\" not in clusters:\n",
    "        clusters[\"PlannedHVLineDist\"] = 99\n",
    "        clusters[\"CurrentHVLineDist\"] = 0\n",
    "    else:\n",
    "        clusters[\"CurrentHVLineDist\"] = 0\n",
    "        clusters = clusters.rename(columns={\"Planned_HVDist\": \"PlannedHVLineDist\"})\n",
    "\n",
    "    if \"Existing_MVDist\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"Existing_MVDist\": \"CurrentMVLineDist\"})\n",
    "        if \"Planned_MVDist\" in clusters:\n",
    "            mask = (clusters['Planned_MVDist'] > clusters['CurrentMVLineDist'])\n",
    "            clusters['Planned_MVDist'][mask] = clusters['CurrentMVLineDist']\n",
    "            clusters = clusters.rename(columns={\"Planned_MVDist\": \"PlannedMVLineDist\"})\n",
    "        else:\n",
    "            clusters[\"PlannedMVLineDist\"] = clusters[\"CurrentMVLineDist\"]\n",
    "    elif \"Existing_MVDist\" not in clusters and \"Planned_MVDist\" not in clusters:\n",
    "        clusters[\"PlannedMVLineDist\"] = 99\n",
    "        clusters[\"CurrentMVLineDist\"] = 0\n",
    "    else:\n",
    "        clusters[\"CurrentMVLineDist\"] = 0\n",
    "        clusters = clusters.rename(columns={\"Planned_MVDist\": \"PlannedMVLineDist\"})\n",
    "\n",
    "    if \"RoadDist\" not in clusters:\n",
    "        clusters[\"RoadDist\"] = 0\n",
    "\n",
    "    if \"Transforme\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"Transforme\": \"TransformerDist\"})\n",
    "    elif \"TransformerDist\" not in clusters:\n",
    "        clusters[\"TransformerDist\"] = 0\n",
    "\n",
    "    if \"Hydropower\" not in clusters:\n",
    "        clusters[\"Hydropower\"] = 0\n",
    "\n",
    "    if \"Hydropow_1\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"Hydropow_1\": \"HydropowerDist\"})\n",
    "    elif 'HydropowerDist' not in clusters:\n",
    "        clusters[\"HydropowerDist\"] = 99\n",
    "\n",
    "    if \"Hydropow_2\" in clusters:\n",
    "        clusters = clusters.rename(columns={\"Hydropow_2\": \"HydropowerFID\"})\n",
    "    elif \"HydropowerFID\" not in clusters:\n",
    "        clusters[\"HydropowerFID\"] = 0\n",
    "\n",
    "    if \"IsUrban\" not in clusters:\n",
    "        clusters[\"IsUrban\"] = 0\n",
    "\n",
    "    if \"PerCapitaD\" not in clusters:\n",
    "        clusters[\"PerCapitaDemand\"] = 0\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"PerCapitaD\": \"PerCapitaDemand\"})\n",
    "\n",
    "    if \"HealthDema\" not in clusters:\n",
    "        clusters[\"HealthDemand\"] = 0\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"HealthDema\": \"HealthDemand\"})\n",
    "\n",
    "    if \"EducationD\" not in clusters:\n",
    "        clusters[\"EducationDemand\"] = 0\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"EducationD\": \"EducationDemand\"})\n",
    "\n",
    "    if \"AgriDemand\" not in clusters:\n",
    "        clusters[\"AgriDemand\"] = 0\n",
    "\n",
    "    if \"Commercial\" not in clusters:\n",
    "        clusters[\"CommercialDemand\"] = 0\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Commercial\": \"CommercialDemand\"})\n",
    "\n",
    "    if \"Conflict\" not in clusters:\n",
    "        clusters[\"Conflict\"] = 0\n",
    "\n",
    "    if \"Electrific\" not in clusters:\n",
    "        clusters[\"ElectrificationOrder\"] = 0\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Electrific\": \"ElectrificationOrder\"})\n",
    "\n",
    "    if \"Resident_1\" not in clusters:\n",
    "        clusters[\"ResidentialDemandTier1\"] = 7.74\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Resident_1\": \"ResidentialDemandTier1\"})\n",
    "\n",
    "    if \"Resident_2\" not in clusters:\n",
    "        clusters[\"ResidentialDemandTier2\"] = 43.8\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Resident_2\": \"ResidentialDemandTier2\"})\n",
    "\n",
    "    if \"Resident_3\" not in clusters:\n",
    "        clusters[\"ResidentialDemandTier3\"] = 160.6\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Resident_3\": \"ResidentialDemandTier3\"})\n",
    "\n",
    "    if \"Resident_4\" not in clusters:\n",
    "        clusters[\"ResidentialDemandTier4\"] = 423.4\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Resident_4\": \"ResidentialDemandTier4\"})\n",
    "\n",
    "    if \"Resident_5\" not in clusters:\n",
    "        clusters[\"ResidentialDemandTier5\"] = 598.6\n",
    "    else:\n",
    "        clusters = clusters.rename(columns={\"Resident_5\": \"ResidentialDemandTier5\"})\n",
    "\n",
    "    clusters[\"X_deg\"] = clusters.geometry.centroid.x\n",
    "\n",
    "    clusters[\"Y_deg\"] = clusters.geometry.centroid.y\n",
    "\n",
    "    clusters.to_file(workspace + r\"\\output.shp\", driver='ESRI Shapefile')\n",
    "    clusters.to_file(workspace + r\"\\output.csv\", driver='CSV')\n",
    "    print(datetime.datetime.now())\n",
    "    return clusters\n",
    "\n",
    "\n",
    "\n",
    "def merge_transmission(proj_path):\n",
    "    current = os.getcwd()\n",
    "    os.chdir(proj_path)\n",
    "    files = os.listdir(proj_path)\n",
    "    shapefiles = []\n",
    "    for file in files:\n",
    "        if file.endswith('.shp'):\n",
    "            f = os.path.abspath(file)\n",
    "            shapefiles += [f]\n",
    "    keyword = 'kV'\n",
    "    tmiss_list = []\n",
    "    for fname in shapefiles:\n",
    "        if keyword in fname:\n",
    "            shpfile = gpd.read_file(fname)\n",
    "            tmiss_list += [shpfile]\n",
    "\n",
    "    gdf = pd.concat([shp for shp in tmiss_list]).pipe(gpd.GeoDataFrame)\n",
    "    gdf.to_file(\"../Projected_files/Concat_Transmission_lines_UMT37S.shp\")\n",
    "    os.chdir(current)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Projected_files_path = sys.argv[1]\n",
    "    #merge_transmission(Projected_files_path)\n",
    "    raster_to_numpyarray()\n",
    "    crs = 'EPSG:3395'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The electrification start forms the demand centers which are classified as electrified and un-electrified within the gridded cells of the 376 cells of Kenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Author: KTH dESA Last modified by Nandi Moksnes\n",
    "# Date: 2020-06\n",
    "# Python version: 3.7\n",
    "import os\n",
    "import sys\n",
    "from ..src.prep_elecstart import settlement_process\n",
    "from onsset import *\n",
    "import pandas as pd\n",
    "\n",
    "#Inputdata that you need to define\n",
    "##Snakemake\n",
    "def main(GIS_files, specs_path):\n",
    "    specs = pd.read_excel(specs_path, index_col=0)\n",
    "    ##Snakemake\n",
    "    output_dir = '../output/'\n",
    "    settlements_in = settlement_process()\n",
    "    settlements_out = os.path.join(output_dir,'settlements.csv')\n",
    "    country = \"Kenya\"\n",
    "    settlements_out_csv = output_dir + '.csv' # os.path.join(output_dir, '{}.csv'.format(country))\n",
    "\n",
    "    onsseter = SettlementProcessor(settlements_in)\n",
    "\n",
    "    pop_actual = specs.loc[\"Kenya\", SPE_POP]\n",
    "    pop_future = specs.loc[\"Kenya\", SPE_POP_FUTURE]\n",
    "    urban_current = specs.loc[\"Kenya\", SPE_URBAN]\n",
    "    urban_future = specs.loc[\"Kenya\", SPE_URBAN_FUTURE]\n",
    "    urban_cutoff = specs.loc[\"Kenya\", SPE_URBAN_CUTOFF]\n",
    "    start_year = int(specs.loc[\"Kenya\", SPE_START_YEAR])\n",
    "    end_year = int(specs.loc[\"Kenya\", SPE_END_YEAR])\n",
    "\n",
    "    elec_actual = specs.loc[country, SPE_ELEC]\n",
    "    pop_cutoff = specs.loc[country, SPE_POP_CUTOFF1]\n",
    "    min_night_lights = specs.loc[country, SPE_MIN_NIGHT_LIGHTS]\n",
    "    max_grid_dist = specs.loc[country, SPE_MAX_GRID_DIST]\n",
    "    max_road_dist = specs.loc[country, SPE_MAX_ROAD_DIST]\n",
    "    pop_tot = specs.loc[country, SPE_POP]\n",
    "    pop_cutoff2 = specs.loc[country, SPE_POP_CUTOFF2]\n",
    "    dist_to_trans = specs.loc[country, SPE_DIST_TO_TRANS]\n",
    "\n",
    "    urban_cutoff, urban_modelled = onsseter.calibrate_pop_and_urban(pop_actual, pop_future, urban_current,\n",
    "                                                                    urban_future, urban_cutoff, start_year, end_year)\n",
    "\n",
    "    min_night_lights, dist_to_trans, max_grid_dist, max_road_dist, elec_modelled, pop_cutoff, pop_cutoff2, rural_elec_ratio, urban_elec_ratio = \\\n",
    "        onsseter.elec_current_and_future(elec_actual, pop_cutoff, dist_to_trans, min_night_lights, max_grid_dist,\n",
    "                                         max_road_dist, pop_tot, pop_cutoff2, start_year)\n",
    "\n",
    "    onsseter.grid_reach_estimate(start_year, gridspeed=9999)\n",
    "\n",
    "    specs.loc[country, SPE_URBAN_MODELLED] = urban_modelled\n",
    "    specs.loc[country, SPE_URBAN_CUTOFF] = urban_cutoff\n",
    "    specs.loc[country, SPE_MIN_NIGHT_LIGHTS] = min_night_lights\n",
    "    specs.loc[country, SPE_MAX_GRID_DIST] = max_grid_dist\n",
    "    specs.loc[country, SPE_MAX_ROAD_DIST] = max_road_dist\n",
    "    specs.loc[country, SPE_ELEC_MODELLED] = elec_modelled\n",
    "    specs.loc[country, SPE_POP_CUTOFF1] = pop_cutoff\n",
    "    specs.loc[country, SPE_POP_CUTOFF2] = pop_cutoff2\n",
    "    specs.loc[country, 'rural_elec_ratio'] = rural_elec_ratio\n",
    "    specs.loc[country, 'urban_elec_ratio'] = urban_elec_ratio\n",
    "\n",
    "\n",
    "    try:\n",
    "        specs.to_excel(specs_path)\n",
    "    except ValueError:\n",
    "        specs.to_excel(specs_path + '.xlsx')\n",
    "\n",
    "    onsseter.df.to_csv(settlements_out_csv, index=False)\n",
    "\n",
    "def elec_current_and_future(self, elec_actual, pop_cutoff, dist_to_trans, min_night_lights,\n",
    "                            max_grid_dist, max_road_dist, pop_tot, pop_cutoff2, start_year):\n",
    "    \"\"\"\n",
    "    Calibrate the current electrification status, and future 'pre-electrification' status\n",
    "    \"\"\"\n",
    "    urban_pop = (self.df.loc[self.df[SET_URBAN] == 2, SET_POP_CALIB].sum())  # Calibrate current electrification\n",
    "    rural_pop = (self.df.loc[self.df[SET_URBAN] < 2, SET_POP_CALIB].sum())  # Calibrate current electrification\n",
    "    total_pop = self.df[SET_POP_CALIB].sum()\n",
    "    total_elec_ratio = elec_actual\n",
    "    urban_elec_ratio = 0.98\n",
    "    rural_elec_ratio = 0.393\n",
    "    factor = (total_pop * total_elec_ratio) / (urban_pop * urban_elec_ratio + rural_pop * rural_elec_ratio)\n",
    "    urban_elec_ratio *= factor\n",
    "    rural_elec_ratio *= factor\n",
    "    # print('factor: ' + str(factor))\n",
    "\n",
    "    logging.info('Calibrate current electrification')\n",
    "    is_round_two = False\n",
    "    grid_cutoff2 = 5\n",
    "    road_cutoff2 = 5\n",
    "    count = 0\n",
    "    prev_vals = []\n",
    "    accuracy = 0.01\n",
    "    max_iterations_one = 30\n",
    "    max_iterations_two = 60\n",
    "    # self.df[SET_ELEC_CURRENT] = 0\n",
    "\n",
    "    # if max(self.df['TransformerDist']) > 0:\n",
    "    #    self.df['GridDistCalibElec'] = self.df['TransformerDist']\n",
    "    #    priority = 1\n",
    "    # elif max(self.df['CurrentMVLineDist']) > 0:\n",
    "    #    self.df['GridDistCalibElec'] = self.df['CurrentMVLineDist']\n",
    "    #    priority = 1\n",
    "    # else:\n",
    "    #    self.df['GridDistCalibElec'] = self.df['CurrentHVLineDist']\n",
    "    #    priority = 2\n",
    "    #\n",
    "    #\n",
    "    # condition = 0\n",
    "    # while condition == 0:\n",
    "    #     # Assign the 1 (electrified)/0 (un-electrified) values to each cell\n",
    "    #     # urban_electrified = 0.159853988426699 * 17573607 * 0.487\n",
    "    #     urban_electrified = urban_pop * urban_elec_ratio\n",
    "    #     # urban_electrified = urban_electrified_modelled * self.df[SET_POP_CALIB].sum() * urban_elec_access\n",
    "    #     # rural_electrified = (1 - 0.159853988426699) * 17573607 * 0.039\n",
    "    #     rural_electrified = rural_pop * rural_elec_ratio\n",
    "    #     # rural_electrified = (1 - urban_electrified_modelled) * self.df[SET_POP_CALIB].sum() * rural_elec_access\n",
    "    #     if priority == 1:\n",
    "    #         self.df.loc[(self.df['GridDistCalibElec'] < 15) & (self.df[SET_NIGHT_LIGHTS] > 0) & (self.df[SET_POP_CALIB] > 5), SET_ELEC_CURRENT] = 1\n",
    "    #         # self.df.loc[(self.df[SET_NIGHT_LIGHTS] > 0) & (self.df[SET_POP_CALIB] > 50), SET_ELEC_CURRENT] = 1\n",
    "    #         # self.df.loc[(self.df['GridDistCalibElec'] < 0.8), SET_ELEC_CURRENT] = 1\n",
    "    #         urban_elec_ratio = urban_electrified / (self.df.loc[(self.df[SET_ELEC_CURRENT] == 1) & (self.df[SET_URBAN] == 2), SET_POP_CALIB].sum())\n",
    "    #         rural_elec_ratio = rural_electrified / (self.df.loc[(self.df[SET_ELEC_CURRENT] == 1) & (self.df[SET_URBAN] < 2), SET_POP_CALIB].sum())\n",
    "    #         pop_elec = self.df.loc[self.df[SET_ELEC_CURRENT] == 1, SET_POP_CALIB].sum()\n",
    "    #         elec_modelled = pop_elec / pop_tot\n",
    "    #     else:\n",
    "    #         self.df.loc[(self.df[SET_NIGHT_LIGHTS] > 0) & (self.df['GridDistCalibElec'] < 5) |  | (self.df[SET_POP_CALIB] > 7000) | (self.df[SET_ROAD_DIST]<3), SET_ELEC_CURRENT] = 1\n",
    "    #         # self.df.loc[(self.df['GridDistCalibElec'] < 0.8), SET_ELEC_CURRENT] = 1\n",
    "    #         urban_elec_ratio = (self.df.loc[(self.df[SET_ELEC_CURRENT] == 1) & (\n",
    "    #                     self.df[SET_URBAN] == 2), SET_POP_CALIB].sum()) / urban_electrified\n",
    "    #         rural_elec_ratio = (self.df.loc[(self.df[SET_ELEC_CURRENT] == 1) & (\n",
    "    #                     self.df[SET_URBAN] < 2), SET_POP_CALIB].sum()) / rural_electrified\n",
    "    #         pop_elec = self.df.loc[self.df[SET_ELEC_CURRENT] == 1, SET_POP_CALIB].sum()\n",
    "    #         elec_modelled = pop_elec / pop_tot\n",
    "\n",
    "    while True:\n",
    "        self.df[SET_ELEC_CURRENT] = self.df.apply(lambda row:\n",
    "                                                  1\n",
    "                                                  if ((row[SET_NIGHT_LIGHTS] > 0 or\n",
    "                                                       row[SET_POP_CALIB] > pop_cutoff and\n",
    "                                                       row['CurrentHVLineDist'] < max_grid_dist or\n",
    "                                                       row[SET_ROAD_DIST] < max_road_dist))\n",
    "                                                  # or (row[SET_POP_CALIB] > pop_cutoff2 and\n",
    "                                                  # (row['CurrentHVLineDist'] < grid_cutoff2 or\n",
    "                                                  # row[SET_ROAD_DIST] < road_cutoff2))\n",
    "                                                  else 0, axis=1)\n",
    "\n",
    "        # Get the calculated electrified ratio, and limit it to within reasonable boundaries\n",
    "        pop_elec = self.df.loc[self.df[SET_ELEC_CURRENT] == 1, SET_POP_CALIB].sum()\n",
    "        elec_modelled = pop_elec / pop_tot\n",
    "\n",
    "        if elec_modelled == 0:\n",
    "            elec_modelled = 0.01\n",
    "        elif elec_modelled == 1:\n",
    "            elec_modelled = 0.99\n",
    "\n",
    "        if abs(elec_modelled - elec_actual) < accuracy:\n",
    "            break\n",
    "        elif not is_round_two:\n",
    "            min_night_lights = \\\n",
    "            sorted([0, min_night_lights - min_night_lights * 2 * (elec_actual - elec_modelled) / elec_actual, 1])[1]\n",
    "            pop_cutoff = \\\n",
    "            sorted([0.01, pop_cutoff - pop_cutoff * 0.5 * (elec_actual - elec_modelled) / elec_actual, 100000])[1]\n",
    "            max_grid_dist = \\\n",
    "            sorted([0.5, max_grid_dist + max_grid_dist * 2 * (elec_actual - elec_modelled) / elec_actual, 60])[1]\n",
    "            max_road_dist = \\\n",
    "            sorted([0.5, max_road_dist + max_road_dist * 2 * (elec_actual - elec_modelled) / elec_actual, 5])[1]\n",
    "        elif elec_modelled - elec_actual < 0:\n",
    "            pop_cutoff2 = sorted([0.01, pop_cutoff2 - pop_cutoff2 *\n",
    "                                  (elec_actual - elec_modelled) / elec_actual, 100000])[1]\n",
    "        elif elec_modelled - elec_actual > 0:\n",
    "            pop_cutoff = sorted([0.01, pop_cutoff - pop_cutoff * 0.5 *\n",
    "                                 (elec_actual - elec_modelled) / elec_actual, 10000])[1]\n",
    "            #\n",
    "        constraints = '{}{}{}{}{}'.format(pop_cutoff, min_night_lights, max_grid_dist, max_road_dist, pop_cutoff2)\n",
    "        if constraints in prev_vals and not is_round_two:\n",
    "            logging.info('Repeating myself, on to round two')\n",
    "            prev_vals = []\n",
    "            is_round_two = True\n",
    "        elif constraints in prev_vals and is_round_two:\n",
    "            logging.info('NOT SATISFIED: repeating myself')\n",
    "            print('2. Modelled electrification rate = {}'.format(elec_modelled))\n",
    "            if 'y' in input('Do you want to rerun calibration with new input values? <y/n>'):\n",
    "                count = 0\n",
    "                is_round_two = False\n",
    "                pop_cutoff = float(input('Enter value for pop_cutoff: '))\n",
    "                min_night_lights = float(input('Enter value for min_night_lights: '))\n",
    "                max_grid_dist = float(input('Enter value for max_grid_dist: '))\n",
    "                max_road_dist = float(input('Enter value for max_road_dist: '))\n",
    "                pop_cutoff2 = float(input('Enter value for pop_cutoff2: '))\n",
    "                break\n",
    "        else:\n",
    "            prev_vals.append(constraints)\n",
    "\n",
    "        if count >= max_iterations_one and not is_round_two:\n",
    "            logging.info('Got to {}, on to round two'.format(max_iterations_one))\n",
    "            is_round_two = True\n",
    "        elif count >= max_iterations_two and is_round_two:\n",
    "            logging.info('NOT SATISFIED: Got to {}'.format(max_iterations_two))\n",
    "            print('2. Modelled electrification rate = {}'.format(elec_modelled))\n",
    "            if 'y' in input('Do you want to rerun calibration with new input values? <y/n>'):\n",
    "                count = 0\n",
    "                is_round_two = False\n",
    "                pop_cutoff = int(input('Enter value for pop_cutoff: '))\n",
    "                min_night_lights = int(input('Enter value for min_night_lights: '))\n",
    "                max_grid_dist = int(input('Enter value for max_grid_dist: '))\n",
    "                max_road_dist = int(input('Enter value for max_road_dist: '))\n",
    "                pop_cutoff2 = int(input('Enter value for pop_cutoff2: '))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        count += 1\n",
    "        rural_elec_ratio = 1\n",
    "        urban_elec_ratio = 1\n",
    "\n",
    "    logging.info('The modelled electrification rate achieved is {}. '\n",
    "                 'If this is not acceptable please revise this part of the algorithm'.format(elec_modelled))\n",
    "    condition = 1\n",
    "\n",
    "    self.df[SET_ELEC_FUTURE_GRID + \"{}\".format(start_year)] = \\\n",
    "        self.df.apply(lambda row: 1 if row[SET_ELEC_CURRENT] == 1 else 0, axis=1)\n",
    "    self.df[SET_ELEC_FUTURE_OFFGRID + \"{}\".format(start_year)] = self.df.apply(lambda row: 0, axis=1)\n",
    "    self.df[SET_ELEC_FUTURE_ACTUAL + \"{}\".format(start_year)] = \\\n",
    "        self.df.apply(lambda row: 1 if row[SET_ELEC_FUTURE_GRID + \"{}\".format(start_year)] == 1 or\n",
    "                                       row[SET_ELEC_FUTURE_OFFGRID + \"{}\".format(start_year)] == 1 else 0, axis=1)\n",
    "    self.df[SET_ELEC_FINAL_CODE + \"{}\".format(start_year)] = \\\n",
    "        self.df.apply(lambda row: 1 if row[SET_ELEC_CURRENT] == 1 else 99, axis=1)\n",
    "\n",
    "    return min_night_lights, dist_to_trans, max_grid_dist, max_road_dist, elec_modelled, pop_cutoff, pop_cutoff2, rural_elec_ratio, urban_elec_ratio\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    GIS_files_path, specs_path = sys.argv[1:]\n",
    "    main(GIS_files_path, specs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create electrified and un-electrified demandhubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In GIS join the step 3. gridded shape file with step 5 shape file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Assign demand to demandhubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In GIS do:\n",
    "- raster to point with GDP to demand hubs.\n",
    "calculate the electrified population\n",
    "with following equation\n",
    "![alt text](Isolated.png \"Title\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
